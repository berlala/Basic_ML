{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#import tensorwatch as tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6355, 5)\n"
     ]
    }
   ],
   "source": [
    "# Train Data load\n",
    "race_data = np.load('race_data_mit_222010103.npz')\n",
    "swa_cmd = race_data['swa_cmd']\n",
    "tho_cmd = race_data['tho_cmd']\n",
    "brk_cmd = race_data['brk_cmd']\n",
    "vx = race_data['vx']\n",
    "vy = race_data['vy']\n",
    "ax = race_data['ax']\n",
    "ay = race_data['ay']\n",
    "\n",
    "data = np.stack((ax,vx,tho_cmd,brk_cmd,swa_cmd),axis=0) # 总数据5维\n",
    "data = np.transpose(data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6355, 5)\n",
      "(5, 2)\n"
     ]
    }
   ],
   "source": [
    "#多维归一化  返回数据和最大最小值\n",
    "def NormalizeMult(data):\n",
    "    data = np.array(data)\n",
    "    normalize = np.arange(2*data.shape[1],dtype='float64')\n",
    "    normalize = normalize.reshape(data.shape[1],2)\n",
    "    for i in range(0,data.shape[1]): #第i列  \n",
    "        listi = data[:,i]\n",
    "        listlow,listhigh =  np.percentile(listi, [0, 100])\n",
    "        # print(i)\n",
    "        normalize[i,0] = listlow\n",
    "        normalize[i,1] = listhigh\n",
    "        delta = listhigh - listlow\n",
    "        if delta != 0: #第j行\n",
    "            for j in range(0,data.shape[0]):\n",
    "                data[j,i]  =  (data[j,i] - listlow)/delta\n",
    "        #np.save(\"./normalize.npy\",normalize)\n",
    "    return  data,normalize\n",
    "\n",
    "data_norm,normalize = NormalizeMult(data)\n",
    "print(data_norm.shape)\n",
    "print(normalize.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data_norm, look_back):\n",
    "    ratio = 0.8\n",
    "    # 创建训练集\n",
    "    data_X, data_Y = [],[]\n",
    "    for i in range(len(data_norm)-look_back):\n",
    "        a = data_norm[i:(i+look_back)]\n",
    "        data_X.append(a)\n",
    "        data_Y.append(data_norm[i+look_back,0]) # inly \n",
    "    # 划分训练集和测试集\n",
    "    train_size = int(len(data_X)*ratio)\n",
    "    #print(train_size)\n",
    "    test_size = len(data_X) - train_size\n",
    "    train_X = data_X[:train_size]\n",
    "    train_Y = data_Y[:train_size]\n",
    "    test_X = data_X[train_size:]\n",
    "    test_Y = data_Y[train_size:]\n",
    "    \n",
    "    return np.array(train_X),np.array(train_Y),np.array(test_X), np.array(test_Y), data_X,data_Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1269, 10, 5)\n",
      "(1269,)\n",
      "6345\n",
      "10\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "tr_x, tr_y,te_x,te_y,data_X, data_Y = create_dataset(data_norm,10)\n",
    "\n",
    "print(te_x.shape)  # 训练集\n",
    "print(te_y.shape) # 测试集\n",
    "print(len(data_X))\n",
    "print(len(data_X[0]))\n",
    "print(len(data_X[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM网络包装函数\n",
    "class RegLSTM(nn.Module):\n",
    "    def __init__(self, inp_dim, out_dim, mid_dim, mid_layers):\n",
    "        super(RegLSTM, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(inp_dim, mid_dim, mid_layers)  # rnn\n",
    "        self.reg = nn.Sequential(\n",
    "            nn.Linear(mid_dim, mid_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(mid_dim, out_dim),\n",
    "        )  # regression\n",
    "        #self.reg = nn.Linear(mid_dim,out_dim)\n",
    "\n",
    "        # x = feature\n",
    "    def forward(self, x):\n",
    "        y = self.rnn(x)[0]  # y, (h, c) = self.rnn(x)\n",
    "\n",
    "        seq_len, batch_size, hid_dim = y.shape\n",
    "        y = y.view(seq_len*batch_size, hid_dim)\n",
    "        y = self.reg(y)\n",
    "        y = y.view(seq_len, batch_size, -1)\n",
    "        return y\n",
    "\n",
    "    \"\"\"\n",
    "    PyCharm Crtl+click nn.LSTM() jump to code of PyTorch:\n",
    "    Examples::\n",
    "        >>> rnn = nn.LSTM(10, 20, 2)\n",
    "        >>> input = torch.randn(5, 3, 10)\n",
    "        >>> h0 = torch.randn(2, 3, 20)\n",
    "        >>> c0 = torch.randn(2, 3, 20)\n",
    "        >>> output, (hn, cn) = rnn(input, (h0, c0))\n",
    "    \"\"\"\n",
    "\n",
    "    def output_y_hc(self, x, hc):\n",
    "        y, hc = self.rnn(x, hc)  # y, (h, c) = self.rnn(x)\n",
    "\n",
    "        seq_len, batch_size, hid_dim = y.size()\n",
    "        y = y.view(-1, hid_dim)\n",
    "        y = self.reg(y)\n",
    "        y = y.view(seq_len, batch_size, -1)\n",
    "        return y, hc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_x.size(): torch.Size([5076, 5, 10])\n",
      "var_y.size(): torch.Size([5076, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bolinzhao/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([5076, 1, 1])) that is different to the input size (torch.Size([5076, 5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss: 0.00628\n",
      "Epoch: 200, Loss: 0.00448\n",
      "Epoch: 300, Loss: 0.00404\n",
      "Epoch: 400, Loss: 0.00389\n",
      "Epoch: 500, Loss: 0.00379\n",
      "Epoch: 600, Loss: 0.00372\n",
      "Epoch: 700, Loss: 0.00369\n",
      "Epoch: 800, Loss: 0.00367\n",
      "Epoch: 900, Loss: 0.00365\n",
      "Epoch: 1000, Loss: 0.00359\n",
      "Model is ready!\n"
     ]
    }
   ],
   "source": [
    "inp_dim = 10 #输入维度，指特征向量的长度,即上文load_data()中的look_back\n",
    "out_dim = 1 # 输出维度1 \n",
    "mod_dir = '.'\n",
    "\n",
    "'''load data'''\n",
    "ratio = 0.8\n",
    "look_back = inp_dim\n",
    "train_x,train_y,test_x,test_y,data_X,data_Y = create_dataset(data_norm,look_back)\n",
    "train_size = int(len(data_X)*ratio)\n",
    "\n",
    "#需要将数据改变一下形状，因为 RNN 读入的数据维度是 (seq, batch, feature)，\n",
    "#所以要重新改变一下数据的维度，这里只有一个序列，所以 batch 是 1，\n",
    "# feature是一个seq里有几个数，这里是2\n",
    "\n",
    "train_x = train_x.reshape((-1, 5, look_back)) # change from (N,3) to (N,1,3)\n",
    "train_y = train_y.reshape((-1, 1, out_dim))\n",
    "test_x = test_x.reshape((-1, 5,look_back))\n",
    "test_y = test_y.reshape((-1, 1, out_dim))\n",
    "\n",
    "'''build model'''\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = RegLSTM(inp_dim, out_dim, mid_dim=4, mid_layers=2).to(device) # mid_dim即隐藏层维度\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)\n",
    "\n",
    "'''train'''\n",
    "var_x = torch.tensor(train_x, dtype=torch.float32, device=device)\n",
    "var_y = torch.tensor(train_y, dtype=torch.float32, device=device)\n",
    "#var_x = Variable(torch.from_numpy(train_x))\n",
    "#var_y = Variable(torch.from_numpy(train_y))\n",
    "print('var_x.size():', var_x.size())\n",
    "print('var_y.size():', var_y.size())\n",
    "\n",
    "for e in range(1024):\n",
    "    out = net(var_x)\n",
    "    loss = criterion(out, var_y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (e + 1) % 100 == 0:  # 每 100 次输出结果\n",
    "        print('Epoch: {}, Loss: {:.5f}'.format(e + 1, loss.item()))\n",
    "print('Model is ready!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存训练好的网络\n",
    "torch.save(net.state_dict(), '{}/race_lstm.pth'.format(mod_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15830, 5, 10])\n",
      "torch.Size([15830, 5, 1])\n",
      "Using matplotlib backend: TkAgg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb0545fce10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 传统预测，给定输入后，基于过去的n帧状态，预测之后的1帧状态，全量预测\n",
    "net  = net.eval()\n",
    "net  = net.double()\n",
    "data_X = np.array(data_X).reshape(-1,5,inp_dim)\n",
    "data_X = torch.from_numpy(data_X)\n",
    "print(data_X.shape)\n",
    "var_data = Variable(data_X)\n",
    "pred_res = net(var_data)\n",
    "print(pred_res.shape)\n",
    "\n",
    "%matplotlib auto\n",
    "# %matplotlib inline\n",
    "#pred_test = pred_res.view(-1).data.numpy()\n",
    "pred_test = []\n",
    "cout = 0\n",
    "for i in pred_res:\n",
    "    pred_test.append(i[-1])\n",
    "    #plt.plot(range(cout, cout+5), i.detach().numpy()) # 显示所有预测值\n",
    "    cout = cout +1 \n",
    "pred_test  = np.array(pred_test)\n",
    "\n",
    "    \n",
    "plt.plot(pred_test,'r',label = 'pred', linewidth=1.5)\n",
    "plt.plot(np.array(data_Y), 'b', label = 'real')\n",
    "plt.plot([train_size, train_size], [0, 1], label='train | predict')\n",
    "plt.ylabel('Acc[m/s^2]')\n",
    "plt.title('Validate Model on Trainning Lap')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 迁移学习验证\n",
    "#### 使用数据集A训练的模型，在数据集B上进行预测，对比数据集B内真值和预测值的差异。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7977, 5)\n",
      "torch.Size([7967, 5, 10])\n",
      "torch.Size([7967, 5, 1])\n",
      "Using matplotlib backend: TkAgg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb074605f98>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate Data load\n",
    "race_data = np.load('race_data_mit_223010103.npz')\n",
    "swa_cmd = race_data['swa_cmd']\n",
    "tho_cmd = race_data['tho_cmd']\n",
    "brk_cmd = race_data['brk_cmd']\n",
    "vx = race_data['vx']\n",
    "vy = race_data['vy']\n",
    "ax = race_data['ax']\n",
    "ay = race_data['ay']\n",
    "\n",
    "data_vil = np.stack((ax,vx,tho_cmd,brk_cmd,swa_cmd),axis=0) # 总数据5维\n",
    "data_vil = np.transpose(data_vil)\n",
    "print(data_vil.shape)\n",
    "\n",
    "data_norm_vil,normalize = NormalizeMult(data_vil)\n",
    "\n",
    "'''load data'''\n",
    "ratio = 0.95\n",
    "train_x,train_y,test_x,test_y,data_X,data_Y = create_dataset(data_norm_vil,look_back)\n",
    "train_size = int(len(data_X)*ratio)\n",
    "\n",
    "# 模型验证\n",
    "net  = net.eval()\n",
    "net  = net.double()\n",
    "data_X = np.array(data_X).reshape(-1,5,inp_dim)\n",
    "data_X = torch.from_numpy(data_X)\n",
    "print(data_X.shape)\n",
    "var_data = Variable(data_X)\n",
    "pred_res = net(var_data)\n",
    "print(pred_res.shape)\n",
    "\n",
    "%matplotlib auto\n",
    "# %matplotlib inline\n",
    "#pred_test = pred_res.view(-1).data.numpy()\n",
    "pred_test = []\n",
    "cout = 0\n",
    "for i in pred_res:\n",
    "    pred_test.append(i[-1])\n",
    "    #plt.plot(range(cout, cout+5), i.detach().numpy()) # 显示所有预测值\n",
    "    cout = cout +1 \n",
    "pred_test  = np.array(pred_test)\n",
    "\n",
    "    \n",
    "plt.plot(pred_test,'r',label = 'pred', linewidth=1.5)\n",
    "plt.plot(np.array(data_Y), 'b', label = 'real')\n",
    "plt.plot([train_size, train_size], [0, 1], label='train | predict')\n",
    "plt.ylabel('Acc[m/s^2]')\n",
    "plt.title('Validate Model on Other Lap')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
