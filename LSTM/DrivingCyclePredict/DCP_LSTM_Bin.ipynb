{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import scipy.io as sio # for .mat read\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # load the driving cycle data from mat \n",
    "    matfn='./3_WLTP3.mat'\n",
    "    data=sio.loadmat(matfn)\n",
    "    seq_t = np.array(data['T_z'])\n",
    "    seq_v = np.array(data['V_z'])\n",
    "    seq_t = seq_t.astype(float)\n",
    "    seq_v = seq_v.astype(float)    \n",
    "    seq = np.concatenate((seq_v[:1801], seq_t[:1801]), axis=1) # 进行对应拼接\n",
    "    seq = (seq - seq.mean(axis=0)) / seq.std(axis=0) # 数据归一化\n",
    "    return seq_v # 只输出速度信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7ff78bd1cf98>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq= load_data()\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure(1)\n",
    "plt.plot(seq[:,0])\n",
    "plt.xlabel('Index[-]')\n",
    "plt.ylabel('Normalized Spd[m/s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LSTM网络包装函数\n",
    "class BatchLSTM(nn.Module):\n",
    "    def __init__(self, inp_dim, out_dim, mid_dim, mid_layers):\n",
    "        super(BatchLSTM, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(inp_dim, mid_dim, mid_layers)  # rnn\n",
    "        self.reg = nn.Sequential(\n",
    "            nn.Linear(mid_dim, mid_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(mid_dim, out_dim),\n",
    "        )  # regression\n",
    "\n",
    "        # x = feature\n",
    "    def forward(self, x):\n",
    "        y = self.rnn(x)[0]  # y, (h, c) = self.rnn(x)\n",
    "\n",
    "        seq_len, batch_size, hid_dim = y.shape\n",
    "        y = y.view(-1, hid_dim)\n",
    "        y = self.reg(y)\n",
    "        y = y.view(seq_len, batch_size, -1)\n",
    "        return y\n",
    "\n",
    "    def output_y_hc(self, x, hc):\n",
    "        y, hc = self.rnn(x, hc)  # y, (h, c) = self.rnn(x)\n",
    "\n",
    "        seq_len, batch_size, hid_dim = y.size()\n",
    "        y = y.view(-1, hid_dim)\n",
    "        y = self.reg(y)\n",
    "        y = y.view(seq_len, batch_size, -1)\n",
    "        return y, hc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 数据处理（数据切割至Bin）\n",
    "\n",
    "seq =  load_data();\n",
    "def process_data(data, seq_len):\n",
    "    \"\"\"\n",
    "        根据给定的序列data，生成数据集\n",
    "        \n",
    "        数据集分为输入和输出，每一个输入的长度为seq_len，每一个输出的长度为1。\n",
    "        也就是说用seq_len天的数据，对应下一天的数据。\n",
    " \n",
    "        若给定序列的长度为d，将输出长度为(d-seq_len+1)个输入/输出对\n",
    "    \"\"\"\n",
    "    dataset_x , dataset_y = [],[]\n",
    "    for i in range(len(data)-seq_len-1): # 1在此处是被预测帧，即y中对应值\n",
    "        _x = data[i:i+seq_len]\n",
    "        dataset_x.append(_x) #输入\n",
    "        dataset_y.append(data[i+seq_len+1]) #输出\n",
    "    return (np.array(dataset_x), np.array(dataset_y))\n",
    "    \n",
    "data_batch  = process_data(seq,10);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 预测过程\n",
    "def run_DC():\n",
    "    inp_dim = 8 # 输入几帧数据\n",
    "    out_dim = 1 # 预测几帧数据\n",
    "    mod_dir = '.'\n",
    "\n",
    "    '''load data'''\n",
    "    data = load_data()  # axis1: number, year, month\n",
    "    #data_x = np.concatenate((data[:-2, 0:1], data[+1:-1, 0:1]), axis=1)\n",
    "    #data_y = data[2:, 0]\n",
    "    data_x, data_y  = process_data(data, inp_dim);\n",
    "    \n",
    "    train_size = int(len(data_x) * 0.9)\n",
    "    train_x = data_x[0:train_size]\n",
    "    train_y = data_y[0:train_size]\n",
    "\n",
    "    # (seq, batch, feature)\n",
    "    train_x = train_x.reshape((-1, 1, inp_dim)) # change from (N,3) to (N,1,3)\n",
    "    train_y = train_y.reshape((-1, 1, out_dim))\n",
    "\n",
    "    '''build model'''\n",
    "    #device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    net = BatchLSTM(inp_dim, out_dim, mid_dim= 16, mid_layers=8).to(device)\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)\n",
    "\n",
    "    '''train'''\n",
    "    var_x = torch.from_numpy(train_x)\n",
    "    var_y = torch.from_numpy(train_y)\n",
    "    #var_x = torch.tensor(train_x, dtype=torch.float32, device=device)\n",
    "    #var_y = torch.tensor(train_y, dtype=torch.float32, device=device)\n",
    "    #print('var_x.size():', var_x.size())\n",
    "    #print('var_y.size():', var_y.size())\n",
    "\n",
    "    for e in range(1024):\n",
    "        out = net(var_x.float())\n",
    "        loss = criterion(out, var_y.float())\n",
    "       # loss = compute_all_loss() 使用自定义的loss函数\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if (e + 1) % 100 == 0:  # 每 100 次输出结果\n",
    "            print('Epoch: {}, Loss: {:.5f}'.format(e + 1, loss.item()))\n",
    "\n",
    "    torch.save(net.state_dict(), '{}/net_DC.pth'.format(mod_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_eval():\n",
    "    inp_dim = 8\n",
    "    out_dim = 1\n",
    "    mod_dir = '.'    \n",
    "        \n",
    "    '''load data'''\n",
    "    data = load_data() \n",
    "    data_x, data_y  = process_data(data, inp_dim);\n",
    "    data_x = data_x.astype(float)\n",
    "    data_y = data_y.astype(float) \n",
    "\n",
    "    train_size = int(len(data_x) * 0.9)\n",
    "    train_x = data_x[0:train_size]\n",
    "    train_y = data_y[0:train_size]\n",
    "\n",
    "    \n",
    "    train_x = train_x.reshape((-1, 1, inp_dim)) # change from (N,2) to (N,1,2)\n",
    "    train_y = train_y.reshape((-1, 1, out_dim))\n",
    "    \n",
    "    '''eval'''\n",
    "    net = BatchLSTM(inp_dim, out_dim, mid_dim=16, mid_layers=8);\n",
    "    net.load_state_dict(torch.load('{}/net_DC.pth'.format(mod_dir), map_location=lambda storage, loc: storage))\n",
    "    net.eval()  # 转换成测试模式\n",
    "    \n",
    "    \"\"\"\n",
    "    appropriate way of seq prediction:\n",
    "    \"\"\"\n",
    "    test_x = data_x.reshape((-1, 1, inp_dim))\n",
    "    test_x_in = np.copy(test_x);\n",
    "    #print(test_x_in) \n",
    "    test_x_in[train_size:,0,0] = 0  # 删去需要预测的速度信息\n",
    "    #print(test_x_in) \n",
    "    #device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    test_x_in = torch.tensor(test_x_in, dtype=torch.float32, device=device)\n",
    "    for i in range(train_size, len(data) - 1):\n",
    "        test_y = net(test_x_in[:i].float()) # predict 速度\n",
    "        test_x_in[i, 0, 0] = test_y[-1, 0] #将上一帧的预测量作为输入数据的一部分\n",
    "\n",
    "    pred_y = test_x_in.cpu().data.numpy()\n",
    "    pred_y = pred_y[:, 0, 0]\n",
    "    plt.plot(data_y, 'r', label='real', alpha=0.3)\n",
    "    plt.plot([train_size, train_size], [-1, 2], label='train | predict')\n",
    "    plt.plot(pred_y[2:], 'g', label='predict')\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig('lstm.png')\n",
    "    plt.pause(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss: 7.21894\n",
      "Epoch: 200, Loss: 7.21750\n",
      "Epoch: 300, Loss: 7.21850\n",
      "Epoch: 400, Loss: 7.21839\n",
      "Epoch: 500, Loss: 7.21835\n",
      "Epoch: 600, Loss: 7.21829\n",
      "Epoch: 700, Loss: 7.21822\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    run_DC()\n",
    "    run_eval()\n",
    "    \n",
    "    #run_origin_Demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:LSTM]",
   "language": "python",
   "name": "conda-env-LSTM-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
